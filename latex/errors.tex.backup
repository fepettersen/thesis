In this numerical setup we will potentially introduce several new error sources in addition to the nomal errors introduced by numerical solution of any equation. 
When a part of the solution acquired is replaced by the solution from another model, which in this case is stochastic, we will change the initial condition to the next iteration in time. 
This might have a number of effects on our final solution. 
When we solve a differential equation numerically we only get an approximation to the actual solution because we are using approximate derivatives (see figure \ref{illustrate_approximate_derivatives}). 
We can investigate this type of error by doing two simulations of the same problem, but replacing the solution in one of the simuations in some area by the random walk model for one timestep. 

\begin{lstlisting}
 path = '/home/fredriep/Dropbox/uio/thesis/doc/results/experiment_03102013_1218/results/'
import glob

i = [];e = [];s = []

for excl in sorted(glob.glob(path+'Excl*')):
	e.append(np.load(excl))

for incl in sorted(glob.glob(path+'Incl*')):
	i.append(np.load(incl))

for j in xrange(len(i)):
	s.append(np.max(np.abs(i[j]-e[j])))
	print s[-1]
\end{lstlisting}
As we can see this will print the maximum absolute difference between the two solutions. 
Since we are dealing with a diffusion process we expect that the first timestep should have the largest error and that the error will in time be killed by the diffusion process. 
\begin{lstlisting}
[...]
0.0
0.025832
0.0054384
0.00360192
0.00212352
0.0016940416
0.0012704
0.001173512704
0.0009942699008
0.00093037021184
0.00083786862592
0.000782433954202
0.000723955260948
0.000680186522141
0.000638864266527
0.000604769629612

\end{lstlisting}
The error is larger than $\Delta t$ by a factor of $10$ ($\Delta t = 0.002$)... 
This might be improved by increasing the number of walkers, or finding a better steplength for the walkers as well as improving the walk-algorithm etc..
The above results were obtained by using the previous timestep as input to the random walk solver. 
In most numerical algorithms (Euler-Chromer etc) one will benefit from using the newest timestep as early as possible. 
Doing the same experiment with the modification of using the latest timestep as input to the random walk solver we obtain the following:
\begin{lstlisting}
[...]
0.0
0.06
0.014
0.0072
0.0036
0.00232
0.0014912
0.0011744
0.000803712
0.000703744
0.00059240448
0.000536887296
0.0004960012288
0.00047304564736
0.000437414641664
0.00041956655104
\end{lstlisting}
That is, the initial error is larger, but it is reduced faster.