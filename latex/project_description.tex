\documentclass[main.tex]{subfiles}

\begin{document}
 This chapter describes both the scope of this project and the various places where a lot of time was spent.

\section{The project}
In the fall of 2014 a new interdisciplinary research project on brain plasticity will start at the University of Oslo and will include people from biology, neuroscience, statistical mechanics and applied mathematics among others. 
There are many processes in the brain which are difficult to describe in any methodology, and in that manner behave as meso-scale processes. 
Processes which are on a length scale between continuum and statistical mechanics. 
Today, there are some alternatives which might be plausible alternatives for modeling such processes, namely molecular dynamics and various offspring of this like direct simulation Mote Carlo. 
Both of which possess a few problems. 

Molecular dynamics seek to model systems of atoms or molecules by Newtonian mechanics in the sense that each particle is affected by some well known potential which in turn lets us calculate the forces on the particle, and integrate the position. 
Though these calculations are a viable alternative in many applications, like nanoporous fluid flow, they suffer from the weakness of immense computational cost and can only effectively model something like a few cubic micrometers. 
More importantly, they are limited to small molecules like SiO$_2$ or water, and to my knowledge no potential is known which might describe macromolecules like proteins or enzymes. 

Direct simulation Monte Carlo is a more plausible candidate than normal molecular dynamics. 
(To my knowledge) it replaces the computationally costly potential calculations with Monte Carlo simulation by drawing some number of random particle-pairs which collide and give each particle a new velocity by some rule (like conservation of temperature). 
This is done in combination with calculating collisions with any walls which might be present in the system. 
Although DSMC is a sort of scaled up version of MD it too suffers from some problems which might make it unsuitable for modeling processes in the brain. 
DSMC is mainly tailored to recreate the properties of Argon gas. This does not have to be as big a weakness as it sounds; it only means that charge neutrality is assumed. 


This thesis enters as the first attempt at trying to combine a well known continuum model of diffusion processes with stochastic model of the same diffusion process. 
Although this might seem a bit unnecessary at first there are quite a few diffusion processes in the brain where this might be the only reasonable model. 
For example, the extracellular space in gray-matter is so narrow in some places that it is problematic to assume continuity. 
Transport processes in and out of dentritic spines are also assumed to be diffusion governed, but only consist of some ten or less particles (this converts to $\frac{\text{nMol}}{\text L}$ concentrations). 

\section{Progress of the project}
The combination of stochastic and continuum models immediately raise the question of where the limit between the two scales is. 
As was done by \emph{dendritic solidification article} one way to postpone answering this question is by introducing some conversion parameter, which will define how many stochastic units one unit of concentration is equivalent to. 
In addition to this, the initial model was built with testing in mind, which makes the exact limit rather uninteresting. 

The stochastic model chosen in this project is random walks because of its mathematical equivalence to the diffusion equation (see sections \ref{further_introduction} and \ref{more_general_random_walks}), its conceptual simplicity and because of how easy it is to add complexity to the model. 
Seeing as there is a mathematical equivalence between the two models an initial goal was to force the error-term from the random walk part of the solver to smaller than the error term from the numerical solution of the partial differential equation. 
A lot of time went into making this work by experimenting with the required conversion ratio, the required number of time-steps in the random walk model per time-step on the PDE solver, various curve-fitting possibilities and a lot of (needless) debugging. 
At one point it seemed that everything behaved as expected, but this turned out to be a bug which meant doing even more testing an needless debugging. 
Finally, and explanation to the difficulty of this seemingly simple problem was found (see section \ref{}) and no more attempts were done. 

After forcing the error terms to behave properly was abandoned, an attempt at combining the diffusion equation solver with DSMC code developed by Anders Hafreager during his masters thesis was made. 
Although this combination to some extent works, it suffers from a difference in dimensionality. 
The DSMC code runs in three spatial dimensions, whereas the code developed in this thesis at the moment is limited to two spatial dimensions because more were not required. 
The extension to three spatial dimensions should not be too hard, however, and both the ``backened'' linear algebra solver and the random walk module should already support 3d modeling. 

Finally, to prove that the developed software can be used to something reasonable it was slightly modified to fit a real life diffusion problem in which an enzyme diffuses through a wide dendrite into a very narrow dendritic spine ($<1\mu$m). 
A thorough description of this problem is found in section \ref{}.
The formalism of the software also allows for testing of diffusion processes where spines are added and/or removed from the dendrite by some conservation rule as observed in some real life systems \cite{}.


\section{What is computational neuroscience}
Neuroscience is the scientific study of the nervous system, but in the traditional sense it focuses very much on what parts of the brain are responsible for what. 
Mathematical neruroscience is more focused on the physics and chemistry involved in the different parts of the brain and nervous system. 
An example of the power of this approach is the classical work done by Hodgkin and Huxley in 1952, earning them the Nobel price in Physiology or medicine in 1963. 
Through four non-linear coupled differential equations they were able to predict the propagation speed of signals along the squid giant axon to a quite high precision. \\

% Copied from the project

The human brain consists of two types of cells; the neurons and neuroglia. 
Neurons are tasked with signal processing and transport, while the glial cells are thought to have more janitorial tasks. 
The neurons are bathed in a salt solution that is mainly $Na^+$ and $Cl^-$. 
Inside the neurons, a highly regulated salt solution of mainly $K^+$ sets up a potential difference relative to the outside of the cell of approximately $-65$mV.
The neurons are in constant communication with each other through action potentials, which are disturbances in the membrane potentials of neurons. 
These action potentials are generated in the body of the cell, called the soma, from where they propagate down the axon without loss of amplitude. 
This is achieved by constantly amplifying the signal using ion pumps (see the Hodgin-Huxley model of the action potential \cite{graham2011principles}).
After propagating down the axon, the action potential reaches a synapse which is a gate to another neuron. 
If the action potential is of significant strength, vesicles carrying neurotransmitters merge with the synapse membrane, letting the neurotransmitters diffuse to the Post Synaptic Density (PSD\nomenclature{PSD}{Post Synaptic Density} of a spine on the receiving dendrite.
If enough neurotransmitters reach the post-synaptic side, the signal continues propagating to the soma of this neuron, and the entire process starts over again. \\
The storage of memories on a sub-cellular level is thought to partly lie in the strengthening or weakening of the receiving synapse end, the PSD \cite{}. 
Familiar impressions will cause similar firing patterns in the sense that the same neurons tend to fire action potentials, which in turn are received by the same neurons each time. 
If the receiving synapses are strengthened or weakened the resulting integrated signals sent to the cell body will be hastened or held back accordingly and the response is strengthened and more time-efficient (DEFINETELY CITE SOMETHING HERE, OR JUST REWRITE... \cite{}). 
The strengthening of synapses is known as long-term potentiation (LTP\nomenclature{LTP}{Long-term potentiation}, and the weakening of synapses is known as long-term depression (LTD\nomenclature{LTD}{Long-term depression}). \\

LTP has been coupled directly with the enzyme protein kinase C${\gamma}$ (PKC$\gamma$\nomenclature{PKC$\gamma$}{protein kinase C${\gamma}$}. 
The dynamics of the actual process is, in part, what will be modeled in this project. 
According to Craske et.al \cite{craske2005spines} PKC$\gamma$ is released into the intracellular plasma of a neuron after being triggered by an increased concentration of calcium ions (Ca$^{2+}$).
 
\end{document}
