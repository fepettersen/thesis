\section{Various calculations}

In this appendix some more tedious and rather boring, but no less important calculations can be found. 
We will also list some algorithms that are important, but not quite in the scope of this thesis.

\subsection{Backward Euler scheme in 2D}

Using the BE discretization on the simple 2D diffusion equation will yield the general scheme in equation \ref{general_scheme_BE2D}.
\begin{equation}\label{general_scheme_BE2D}
 u^{n}_{i,j} = \underbrace{\frac{-D\Delta t}{\Delta x^2}}_{\alpha}\left(u^{n+1}_{i+1,j}+u^{n+1}_{i-1,j}\right) +
 \underbrace{\left(1+\frac{2D\Delta t}{\Delta x^2} +\frac{2D\Delta t}{\Delta y^2}\right)}_{\gamma}u^{n+1}_{i,j} 
 \underbrace{-\frac{2D\Delta t}{\Delta y^2}}_{\beta}\left(u^{n+1}_{i,j+1}+u^{n+1}_{i,j-1}\right)
\end{equation}
This can, again, be written as a linear problem where the vectors are simply the matrices $u^n$ and $u^{n+1}$ written as column vectors. 
The matrix is written out for a $3\times3$ grid with no-flux Neumann boundary conditions in equation \ref{linear_system_BE2D}. 
We see that it is a five-band diagonal matrix, and so the tridiagonal solver cannot be used in this case. It is fully possible to use for example a Gaussian elimination in order to solve this equation, but it will require $\frac{2}{3}\mathcal{O}(n^3)$ operations per time step, where n is the size of the matrix (in this case $n=9$). 
Another way to solve this equation, and by extension use the BE scheme, is to use some form of sparse LU decomposition.
\begin{align}\label{linear_system_BE2D}
  \left(\begin{array}{c c c c c c c c c}
        \gamma & -2\beta &0 &-2\alpha &0 &0 &0 &0 &0\\
        -\beta & \gamma & -\beta &0 &-2\alpha &0 &0 &0 &0\\
        0&-2\beta & \gamma & 0 & 0 & -2\alpha &0&0&0\\
        -\alpha& 0&0 & \gamma & -2\beta & 0 & -\alpha &0&0\\
        0& -\alpha&0&-\beta & \gamma & -\beta & 0 & -\alpha &0\\
        0& 0& -\alpha&0&-2\beta & \gamma & 0 & 0 &-\alpha\\
        0& 0 &0 &-2\alpha &0&0 & \gamma & -2\beta&0\\
        0& 0 &0 &0 &-2\alpha&0&-\beta & \gamma &-\beta\\
         0&0 &0 &0&0 &-2\alpha&0&-2\beta & \gamma
       \end{array}\right)\mathbf{u}^{n} = \mathbf{u}^{n+1}
\end{align}
When we try to implement Neumann boundary conditions for grids that are larger than $3\times3$ we come across a problem. 
Doing the matrix-vector multiplication in equation \ref{linear_system_BE2D} reproduces the BE scheme with boundary conditions perfectly. 
However, if we extend to a $4\times4$ grid using a matrix on the same form we will start producing equations which will not arise from the scheme. 
This is illustrated in eqs. \ref{first_eq_BE2D_scheme} and \ref{first_eq_BE2D_linear_system}. 
Moving the off-diagonal entries with $\alpha$ one more column to the right and left will solve the problem, but this will force us to use some more general solver of a sparse linear system. 
All in all we will probably be better off using another scheme (at least in 2D).\\
The first equation that arises from the BE scheme in 2D (where $i=j=0$) is
\begin{equation}\label{first_eq_BE2D_scheme}
 u^n_{0,0} = \gamma u^{n+1}_{0,0}-2\alpha u^{n+1}_{1,0} -2\beta u^{n+1}_{0,1}
\end{equation}
while the first equation produced by the linear system in the $4\times4$ case is 
\begin{equation}\label{first_eq_BE2D_linear_system}
 u^n_{0,0} = \gamma u^{n+1}_{0,0}-2\alpha u^{n+1}_{0,3} -2\beta u^{n+1}_{0,1}
\end{equation}
which is an equation that will never be produced by the BE scheme. 
In the $3\times3$ grid-case the off-diagonal matrix entries with $\alpha$ are on the third column before and after the diagonal. 

Moving the corresponding entries to the fourth column in the $4\times4$ case, and similarly to the n'th column in the $n\times n$ case will fix the problem, but also increase the complexity of the matrix seeing as it will be $n+2$ band diagonal.\\
Extending the model to three spatial dimensions gives a very similar matrix to the 2d-case. 

\begin{align}\label{BE3D_linear_system}
  \left(\begin{array}{c c c c c c c c c}
        D_{00} & -2\beta I &0 &-2\alpha I &0 &0 &0 &0 &0\\
        -\beta I & D_{01} & -\beta I &0 &-2\alpha I &0 &0 &0 &0\\
        0&\ddots & \ddots & 0 & 0 & \ddots &0&0&0\\
        -\alpha I& 0&0 & D_{10} & -2\beta I& 0 & -\alpha I &0&0\\
        0& \ddots&0&\ddots & \ddots & \ddots & 0 & \ddots &0\\
        0& 0 &0 &-2\alpha I &0&0 & D_{n0} & -2\beta I&0\\
        0& 0 &0 &0 &\ddots&0&\ddots & \ddots &\ddots\\
         0&0 &0 &0&0 &-2\alpha I&0&-2\beta I & D_{nn}
       \end{array}\right)
       \left(\begin{array}{c}
             u^{n+1}_{00k}\\
             u^{n+1}_{01k}\\
             \dots\\
             u^{n+1}_{10k}\\
             \dots\\
             u^{n+1}_{n0k}\\
             \dots\\
             u^{n+1}_{nnk}
             \end{array}\right) = \mathbf{u}^{n}
\end{align}
In equation \ref{BE3D_linear_system} $I$ denotes the $n\times n$ identity, $D_{ij}$ denotes the tridiagonal $n\times n$ matrix with entries similar to the ones in eq. \ref{general_scheme_BE2D}, and off-diagonal entries similar to the ones in eq. \ref{general_scheme_BE2D}. 
All $0$'s denote the $n\times n$ zero-matrix. The values $\alpha$ and $\beta$ are the relevant coefficient matrices for the calculations in question. These will be diagonal as well (or simly numbers in the isotropic case). 
Note also that the vector entries $u^{n+1}_{ijk}$ are column vectors, making the vector $\mathbf{u}^{n+1}$ have the shape $1\times n^3$.

% \caption{Algorithm for Gaussian elimination of a tridiagonal linear system.}
% \label{tridiag}

\section{Debugging}\label{debugging}

In any project which involves programming one is bound to do some debugging. This project is no exception. 
Debugging can be extremely frustrating because no-one sees all the hours that go into finding the bugs, only the ones that do not (when the bug is not fixed). 
This section will deal with some general techniques for debugging finite difference solvers and random-walk implementations and some special words on how to debug the software developed to combine the two solvers.

\subsection{Compiler/syntax errors}

If you are programming in a compiled language like fortran or C/C++ you will forget some syntax, or misspell it, use a compiler-flag that outputs as much info as possible to terminal (-Wall for the gnu compiler), and start with the errors you understand. If you are building a larger project which requires linking, remember that packages must be linked in the correct order. For example; the armadillo linear algebra library is backened by LAPACK and BLAS. Both these libraries must be linked as well and they must be linked in the following order:
\begin{lstlisting}
 g++ *.cpp -o myprog -O2 -larmadillo -llapack -lblas
\end{lstlisting}
Anything else will give very cryptic compiler errors. \\
If you are using an interpreted language like python or MatLab the interpreter usually gives extensive information about the errors you have done, read them thoroughly!

\subsection{Segmentation faults}
In an interpreted language you will be told exactly where and what is wrong, in compiled languages you will not unless you are using extensions that give you some more information like armadillo. Segmentation faults are often quite simple to find, and most compilers have some sort of debugger which can help you find them. 
The gnu-compiler has an environment called gdb in which you can run your program which will catch seg.-faults and tell you where they are. If you are using some advanced editor like qt creator you can also easily place breakpoints in your code where you can get information about the various variables, instances, attributes etc. of your code at the exact time of the break. You can also step through the code. thoroughly
Some times though the thing that works best is to print things at various places. I like having the possibility that every function in my code can print its name when it is called. There are even some python modules which tells you where it was called from. This will make it very easy to find out when the code went wrong, and what function is the problem.

\subsection{Finite difference methods}
First and foremost: Have a correct discretization. There are (probably) webpages which can discretize your equation(s) for you, but it is almost always useful to do this by hand. 
It will help you in your further debugging. \\
There is one very important rule in programming in general: ``First make it work, then make right, then make it fast''. 
For implementing FDMs this means that you should start coding as soon as you have a clear image of what to be implemented, and what dependencies are needed. You will need a well defined initial condition (preferably one where you have the exact solution of the equation) and boundary conditions before you start coding. 
Personally, I like starting with the simplest Dirichlet boundary conditions $u|_{\d \Omega} = 0$ and make them work before I go any further. 
You should note, however, that implicit schemes will be greatly influenced by the choice of boundary conditions.\\
Visualization is invaluable during debugging, seeing as a plot will let you see when and where the error occurs. \emph{Show some example}
Most likely you will now have something wrong with your solution (if not, cudos). This is where you look over your discretization again to make sure that it is correct, and then look over your implementation to check that it actually does what you think it does. 
At this point I would like to introduce rubber-duck debugging which was invented by the C-developer Dennis Ritchie. 
The story goes that he would keep a rubber duck at his desk and whenever he was stuck, would describe the code in detail (what each statement did and was supposed to do) to the rubber duck. Asking questions often reveals a lot of information. 
Personally I like my rubber duck to challenge me, so I prefer to involve a friend, but the concept is the same.\\
When your code seems to reproduce the intended results it is time to start the verification. This is where we make an error estimate and do some numerical analysis (you should of course have checked for the numerical stability of your chosen scheme when you discretized it). 
Making sure your implementation is correct is a lot harder than it sounds, but there are a few points that should be fulfilled:
\begin{itemize}
 \item Manufactured solution\\
 Find some function which fulfills the equation you are working with. Remember that you have a source term which can be whatever you want it to be at this point, meaning that you can more or less decide what solution you want to your equation. 
 \item Stationary solution\\
 This boils down to energy-conservation. If the initial condition is a constant, there should be no time-dependencies (assuming your boundary conditions match; an initial condition $u=1$ with Dirichlet boundaries $u|_{\d \Omega}=0$ will not work), and the solution will be constant.
 \item Exact numerical solution\\
 For a fitting initial condition (and discretization) you will be able to find an exact solution to the discretized equation you are implementing. An example of this is found in chapter \ref{exact_numerical_solution}. Your scheme should reproduce this solution to more or less machine precision. Note that you might run into round-off errors and overflow here in some cases (again, see chapter \ref{exact_numerical_solution}).\\
 \item Convergence test\\
 
\end{itemize}

\subsection{Random walk and Monte Carlo methods}

The main difference between debugging a MC based solver and a deterministic solver is the fact that you often do not have a clear idea of what the results of the intermediate steps should be. 
What you might know (or should know during development), however is the result of the complete MC integration, and some statistical properties of your random numbers. 
Using uniformly distributed random numbers will give you a certain mean and standard deviation, and a Gaussian distribution will give you another. 
You should check that the random number generator (RNG) you chose actually reproduces these properties to a reasonable precision. 
If you are working with random walkers it also helps to look at the behavior of a small number of walkers, to check that they behave more or less as you expect. 
One thing to look out for is the fact that a random walker in both one and two spatial dimensions will fill all space given enough steps. 
Of course enough steps is infinitely many, but if you also implement reflecting boundaries and use some 4-5 walkers you will see a tendency after approximately $10^4$ steps. \\
As we have discussed earlier the fluctuations in a MC-model are usually of a magnitude $\frac{1}{\sqrt N}$ this is also smart to verify. \\
Finally, you should absolutely have the possibility to set the random seed and check that two runs with the same random seed produces the exact same result and makes sure you are using a RNG with a large enough period. The xor-shift algorithm by Geroge Marsagla \cite{} has a period of around $10^48$ which usually is more than adequate.

\subsection{The developed software}

For some 2 months while working with this project I got really good results which seemed to verify all the important par